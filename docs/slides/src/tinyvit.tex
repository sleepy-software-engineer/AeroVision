\section{TinyViT}

\begin{sidepic}{./images/code.png}{TinyViT Architecture}
  \framesubtitle{Our tiny model}
  \begin{itemize}
    \item A minimal Vision Transformer designed for \textbf{smaller datasets}.
    \item Reduces \textbf{architectural complexity} while preserving key transformer principles.
    \item Uses \textbf{fewer layers}, \textbf{smaller embedding dimensions}, and computationally efficient components.
  \end{itemize}
\end{sidepic}

\begin{frame}[fragile]{TinyViT Parameters}
  \framesubtitle{What parameters do we use ?}
  \begin{table}[htbp]
    \small
    \centering
    \caption{Parameters of the TinyViT Model for CIFAR-10}
    \begin{tabular}{@{}ll@{}}
      \toprule
      \textbf{Parameter} & \textbf{Value} \\
      \midrule
      Number of Classes & 10 \\
      Embedding Dimension & 128 \\
      Image Size & 32 \\
      Patch Size & 4 \\
      Input Channels & 3 \\
      Number of Attention Heads & 8 \\
      Number of Transformer Layers & 6 \\
      MLP Hidden Dimension & 512 \\
      \bottomrule
    \end{tabular}
  \end{table}
\end{frame}

\begin{frame}{Differences between TinyViT and ViT}
  \framesubtitle{Some differences between the two models}
  \begin{itemize}
    \item TinyViT has significantly \textbf{fewer transformer layers} than standard ViT.
    \item Smaller embedding dimensions to \textbf{reduce computational costs}.
    \item Optimized for smaller datasets, unlike ViT, which requires \textbf{large scale pretraining}.
    \item \textbf{Lower memory footprint}, making it feasible for resource constrained environments.
  \end{itemize}
\end{frame}