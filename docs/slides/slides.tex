\documentclass{beamer}
\usepackage{amsfonts,amsmath,oldgerm}
\usepackage{tabularx, booktabs, multirow, siunitx}
\usetheme{sintef}

\newcommand{\testcolor}[1]{\colorbox{#1}{\textcolor{#1}{test}}~\texttt{#1}}

\usefonttheme[onlymath]{serif}

\titlebackground*{assets/background}

\newcommand{\hrefcol}[2]{\textcolor{cyan}{\href{#1}{#2}}}

\title{TinyVit: A Small Vision Transformer}
\course{Master's Degree in Computer Science}
\author{\href{mailto:crainic1938430@studenti.uniroma1.it}{Lucian Dorin Crainic}}
\IDnumber{1938430}
\date{Academic Year 2024/2025}

\begin{document}
\maketitle

\begin{frame}

  This project is based on the well known \textbf{Vision Transformer} (ViT) architecture, a deep learning model that applies self attention mechanisms to image processing. We will start by introducing the core principles of ViT, explaining how it differs from traditional CNNs.

  \vspace{\baselineskip}

  Then, we will explore the \textbf{TinyViT} a smaller implementation of the ViT architecture. Finally, we will present benchmark results demonstrating its performance across various tasks.

\end{frame}

\input{src/introduction.tex}
\input{src/vit.tex}
\input{src/tinyvit.tex}
\input{src/dataset.tex}

\input{src/training.tex}
\input{src/results.tex}

\input{src/conclusions.tex}

\backmatter

\end{document}