\section{Conclusion and Future Work}
In this chapter a conclusion is drawn from the results obtained in the previous chapter. The chapter also discusses the future work that can be done to improve the model.

\subsection{Conclusion}
In conclusion, the implementation of the Tiny ViT architecture has shown promising results, often performing on par with, and occasionally surpassing, standard Convolutional Neural Networks (CNNs) in image recognition tasks. This achievement underscores the potential of Vision Transformers (ViTs) as a robust alternative to the well-established CNNs, offering exploration beyond conventional CNN implementations. While we did not achieve the performance levels of the standard ViT architecture, primarily due to the absence of large-scale datasets for pre-training and subsequent transfer learning, we successfully demonstrated that a scaled-down ViT architecture can obtain good results without the need for massive datasets.
\subsection{Future Work}
Future work to evaluate the performance of the proposed tiny Vision Transformer (ViT) architecture on two key computer vision tasks: object detection and semantic segmentation. Specifically, the tiny ViT could be implemented forr frameworks like DETR \cite{carion2020end} for object detection and Segmenter \cite{strudel2021segmenter} for segmentation, enabling a direct comparison with simpler CNN-based architectures traditionally used for these tasks. Additionally, the Tiny ViT architecture could be further optimized by exploring different hyperparameters, such as the number of layers, hidden units, and attention heads, to improve its performance.